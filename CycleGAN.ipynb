{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVfnqCmR5O2vdvWifBnwB0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akiyoshi-Yagi/GANs/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w296Z46FpI_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa71b769-5fd2-4871-f8cd-915c561e6630"
      },
      "source": [
        "import scipy as sp\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho7pr6mEvLYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4999c503-1160-4140-96ba-336d24cde757"
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-9odn4rui\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-9odn4rui\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=05d6bdb6aa05b9e0f9d63fa81d69078ed1f25e275d71b9b7f83f3b37d73cd608\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m6v5o1_z/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKEQQmd0vL7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import scipy\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"val\"\n",
        "        path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))\n",
        "        path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))\n",
        "\n",
        "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        # Sample n_batches * batch_size from each path list so that model sees all\n",
        "        # samples from both domains\n",
        "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img_A, img_B in zip(batch_A, batch_B):\n",
        "                img_A = self.imread(img_A)\n",
        "                img_B = self.imread(img_B)\n",
        "\n",
        "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
        "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img_A = np.fliplr(img_A)\n",
        "                        img_B = np.fliplr(img_B)\n",
        "\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            yield imgs_A, imgs_B\n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HktW6sPlwRbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CycleGAN():\n",
        "  def __init__(self):\n",
        "    self.img_rows = 128\n",
        "    self.img_cols = 128\n",
        "    self.chanenels = 3\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "    self.dataset_name = \"apple2orange\"\n",
        "    self.data_loader = DataLoader(dataset_name=self.dataset_name, img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "    patch = int(self.img_rows / 2 ** 4)\n",
        "    self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "    self.gf =  32\n",
        "    self.df =  64\n",
        "\n",
        "    #ここのハイパーパラメータは実験によって最適な数値を求める！\n",
        "    #cycle consistnecy lossの重み\n",
        "    self.lambda_cycle = 10.0\n",
        "    #identity lossの重み\n",
        "    self.lambda_id = 0.9 * self.lambda_cycle\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    #ネットワーク構築\n",
        "\n",
        "    #識別器のコンパイル\n",
        "    self.d_A = self.build_discriminator()\n",
        "    self.d_B = self.build_discriminator()\n",
        "    self.d_A.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    self.d_B.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "    #生成器のコンパイル\n",
        "    self.g_AB = self.build_genereator()\n",
        "    self.g_BA = self.build_genereator()\n",
        "\n",
        "    img_A = Input(shape=self.img_shape)\n",
        "    img_B = Input(shape=self.img_shape)\n",
        "\n",
        "    fake_B = self.g_AB(img_A)\n",
        "    fake_A = self.g_BA(img_B)\n",
        "    \n",
        "    reconstr_A = self.g_BA(fake_B)\n",
        "    reconstr_B = self.g_AB(fake_A)\n",
        "    \n",
        "    img_A_id = self.g_BA(img_A)\n",
        "    img_B_id = self.g_AB(img_B)\n",
        "\n",
        "    self.d_A.trainable = False\n",
        "    self.d_B.trainable = False\n",
        "\n",
        "    valid_A = self.d_A(fake_A)\n",
        "    valid_B = self.d_B(fake_B)\n",
        "\n",
        "    self.combined = Model(inputs=[img_A, img_B],\n",
        "                          outputs=[valid_A, valid_B,\n",
        "                                    reconstr_A, reconstr_B,\n",
        "                                    img_A_id, img_B_id])\n",
        "    self.combined.compile(loss=['mse', 'mse','mae', 'mae', 'mae', 'mae'],\n",
        "                          loss_weights=[1, 1,\n",
        "                                        self.lambda_cycle, self.lambda_cycle,\n",
        "                                        self.lambda_id, self.lambda_id],\n",
        "                          optimizer=optimizer)\n",
        "\n",
        "    \n",
        "\n",
        "  #生成器\n",
        "  def build_genereator(self):\n",
        "\n",
        "    def conv2d(layer_input, filters, f_size=4, noramlization=True):\n",
        "      d = Conv2D(filters, kernel_size=f_size, strides=2, padding=\"same\")(layer_input)\n",
        "      d = LeakyReLU(alpha=0.2)(d)\n",
        "      if nomalization:\n",
        "        d = InstanceNormalization()(d)\n",
        "        return d\n",
        "\n",
        "    @staticmethod\n",
        "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "      u = UpSampling2D(size=2)(layer_input)\n",
        "      u = Conv2D(filters, kernel_size=f_size, strides=1, padding=\"same\", activation=\"relu\")(u)\n",
        "      if dropout_rate:\n",
        "        u = Dropout(dropout_rate)(u)\n",
        "      u = InstanceNormalization()(u)\n",
        "      u = Concatenate()([u, skip_input])\n",
        "      return u\n",
        "\n",
        "      #ダウンサンプリング\n",
        "      d0 = Input(shape=self.img_shape)\n",
        "      d1 = self.conv2d(d0, self.gf)\n",
        "      d2 = self.conv2d(d1, self.gf*2)\n",
        "      d3 = self.conv2d(d2, self.gf*4)\n",
        "      d4 = self.conv2d(d3, self.gf*8)\n",
        "\n",
        "      #upsampling\n",
        "      u1 = self.deconv2d(d4, d3, self.gf * 4)\n",
        "      u2 = self.deconv2d(u1, d2, self.gf * 2)\n",
        "      u3 = self.deconv2d(u2, d1, self.gf * 1)\n",
        "      u4 = UpSampling2D(size=2)(u3)\n",
        "\n",
        "      output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding=\"same\", activation=\"tanh\")(u4)\n",
        "\n",
        "      return Model( d0, output_img)\n",
        "  \n",
        "  #識別器\n",
        "  def build_discriminator(self):\n",
        "    img = Input(shape=self.img_shape)\n",
        "\n",
        "    d1 = self.conv2d(img, self.df, normalization=False)\n",
        "    d2 = selfconv2d(d1, self.df*2)\n",
        "    d3 = selfconv2d(d2, self.df*4)\n",
        "    d4 = selfconv2d(d3, self.df*8)\n",
        "\n",
        "    validity = Conv2D(1, kernel_size=4, strides=1, padding=\"same\")(d4)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "  def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "\n",
        "    valid = np.ones((batch_size,) + disc_patch)\n",
        "    fake =  np.zeros((batch_size, ) + self.disc_patch)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "\n",
        "        #識別器の訓練\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "\n",
        "        dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "        dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "        dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "        dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "        dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "        dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "        #識別器全体の誤差\n",
        "        d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "        #生成器の訓練\n",
        "        g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A, imgs_B, imgs_A, imgs_B])\n",
        "        g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                                                      [valid, valid,\n",
        "                                                       imgs_A, imgs_B,\n",
        "                                                       imgs_A, imgs_B])\n",
        "                # If at save interval => plot the generated image samples\n",
        "        if batch_i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_i)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCPT97XkCZhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cycle_gan = CycleGAN()\n",
        "cycle_gan.train(epochs=100, batch_size=64, sample_interval=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNApVY9CkXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}